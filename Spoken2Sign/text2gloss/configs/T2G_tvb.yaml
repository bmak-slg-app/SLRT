task: T2G
data:
  input_data: videos
  input_streams:
  - rgb
  zip_file: ../../../data/tvb/tvb
  dev: ../../../data/tvb/v5.7_dev_sim.pkl
  test: ../../../data/tvb/v5.7_dev_sim.pkl
  train: ../../../data/tvb/v5.7_dev_sim.pkl
  # vocab_file: ../../../data/phoenix_2014t/phoenix_iso_with_blank.vocab
  dataset_name: tvb
  level: char
  max_sent_length: 400
  txt_lowercase: true
  # blank_as_mask: True
testing:
  cfg:
    recognition:
      beam_size: 1
    translation:
      length_penalty: 1
      max_length: 100
      num_beams: 5
training:
  batch_size: 1  #8
  keep_last_ckpts: 1
  # load_ckpt: results/phoenix-2014t_g2t/ckpts/best.ckpt
  model_dir: ../../../data/tvb/T2G_tvb_lr1e-4
  num_workers: 4
  optimization:
    betas:
    - 0.9
    - 0.998
    learning_rate:
      default: 0.001
      mapper: 0.001
      translation: 1.0e-04
    optimizer: Adam
    scheduler: cosineannealing
    t_max: 80
    weight_decay: 0.001
  overwrite: false
  from_ckpt: true
  random_seed: 17
  shuffle: true
  total_epoch: 80
  validation:
    cfg:
      recognition:
        beam_size: 1
      translation:
        length_penalty: 1
        max_length: 100
        num_beams: 5
    freq: 1
    unit: epoch
model:
  TranslationNetwork:
    input_type: text
    GlossEmbedding:
      freeze: false
      gloss2embed_file: ../../../pretrained_models/mBart_tvb_t2g/gloss_embeddings.bin
    GlossTokenizer:
      gloss2id_file: ../../../pretrained_models/mBart_tvb_t2g/gloss2ids.pkl
      src_lang: zh_CSL
    TextTokenizer:
      pretrained_model_name_or_path: ../../../pretrained_models/mBart_tvb_t2g
      pruneids_file: ../../../pretrained_models/mBart_tvb_t2g/map_ids.pkl
      text2embed_file: ../../../pretrained_models/mBart_tvb_t2g/text_embeddings.bin
      tgt_lang: zh_CN
    freeze_txt_embed: false
    label_smoothing: 0.2
    overwrite_cfg:
      attention_dropout: 0.1
      dropout: 0.3
    pretrained_model_name_or_path: ../../../pretrained_models/mBart_tvb_t2g
